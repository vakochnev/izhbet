#!/usr/bin/env python3
import logging
from typing import List, Tuple

import pandas as pd

from config import Session_pool
from db.models import Feature
from core.constants import TARGET_FIELDS, DROP_FIELD_EMBEDDING


logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


NON_FEATURE_COLUMNS = {
    'id', 'match_id', 'prefix', 'created_at', 'updated_at'
}


def _load_features(limit: int = 10000) -> pd.DataFrame:
    with Session_pool() as db:
        rows: List[Feature] = db.query(Feature).limit(limit).all()
        if not rows:
            return pd.DataFrame()
        return pd.DataFrame([r.as_dict() for r in rows])


def _prepare_feature_df(df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
    if df.empty:
        return df, []

    # Drop non-feature and target columns
    to_drop = set(TARGET_FIELDS) | set(DROP_FIELD_EMBEDDING) | NON_FEATURE_COLUMNS
    existing = [c for c in to_drop if c in df.columns]
    df_feat = df.drop(columns=existing, errors='ignore')

    # Keep only numeric columns and coerce
    for col in df_feat.columns:
        df_feat[col] = pd.to_numeric(df_feat[col], errors='coerce')

    # Return list of feature columns
    feature_cols = list(df_feat.columns)
    return df_feat, feature_cols


def analyze_quality(limit: int = 10000) -> None:
    print("\nüîç –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –§–ò–ß–ï–ô")
    print("=" * 60)

    df = _load_features(limit=limit)
    if df.empty:
        print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ features")
        return

    total_rows = len(df)
    prefixes = df['prefix'].value_counts(dropna=False) if 'prefix' in df.columns else None

    df_feat, feature_cols = _prepare_feature_df(df)
    if df_feat.empty:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ñ–∏—á–∏ (–ø—É—Å—Ç–æ–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏)")
        return

    # Basic stats
    num_features = len(feature_cols)
    print(f"–°—Ç—Ä–æ–∫ (feature-–æ–±—ä–µ–∫—Ç–æ–≤): {total_rows:,}")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Å—Ç–æ–ª–±—Ü–æ–≤): {num_features:,}")

    # Missing rates
    missing_pct = df_feat.isna().mean().sort_values(ascending=False)
    zero_var = (df_feat.nunique(dropna=False) <= 1)
    all_zero = (df_feat.fillna(0).sum(axis=0) == 0)

    num_missing_gt50 = int((missing_pct > 0.5).sum())
    num_zero_var = int(zero_var.sum())
    num_all_zero = int(all_zero.sum())

    print(f"–ö–æ–ª–æ–Ω–æ–∫ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ > 50%: {num_missing_gt50}")
    print(f"–ö–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ (–Ω—É–ª–µ–≤–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è): {num_zero_var}")
    print(f"–ö–æ–ª–æ–Ω–æ–∫, —Å—É–º–º–∞=0: {num_all_zero}")

    # Per-prefix coverage
    if prefixes is not None:
        print("\n–ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ prefix:")
        for p, cnt in prefixes.items():
            print(f"  {p}: {cnt:,}")

    # Top problem columns
    top_missing = missing_pct.head(20)
    if not top_missing.empty:
        print("\n–¢–æ–ø-20 –∫–æ–ª–æ–Ω–æ–∫ –ø–æ –¥–æ–ª–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤:")
        for name, val in top_missing.items():
            print(f"  {name}: {val:.2%}")

    if num_zero_var > 0:
        print("\n–ü—Ä–∏–º–µ—Ä—ã –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫:")
        for name in zero_var[zero_var].index[:20]:
            print(f"  {name}")

    # Feature count per match expectation
    if 'match_id' in df.columns:
        cols_per_prefix = df.groupby('prefix')['match_id'].nunique() if 'prefix' in df.columns else None
        unique_matches = df['match_id'].nunique()
        print(f"\n–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–∞—Ç—á–µ–π –≤ –≤—ã–±–æ—Ä–∫–µ: {unique_matches:,}")
        if cols_per_prefix is not None:
            print("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–∞—Ç—á–µ–π –ø–æ prefix:")
            for p, v in cols_per_prefix.items():
                print(f"  {p}: {int(v):,}")

    print("\n–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –≤—ã—Å–æ–∫–æ–π –¥–æ–ª–µ–π –ø—Ä–æ–ø—É—Å–∫–æ–≤ (>50%) –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ")
    print("- –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –æ–∂–∏–¥–∞–µ–º–æ–µ —á–∏—Å–ª–æ —Ñ–∏—á–µ–π –Ω–∞ –º–∞—Ç—á (–æ–∫–æ–ª–æ 2160)")
    print("- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –±–∞–ª–∞–Ω—Å –ø–æ prefix ('home','away','diff','ratio')")


if __name__ == '__main__':
    analyze_quality()


