#!/usr/bin/env python3
import logging
import numpy as np
import pandas as pd
from typing import Tuple

from sklearn.feature_selection import f_regression, mutual_info_regression

from config import Session_pool
from db.models import Feature
from core.constants import TARGET_FIELDS, DROP_FIELD_EMBEDDING

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


META = {'id', 'match_id', 'prefix', 'created_at', 'updated_at'}


def load_dataset(limit_matches: int = 5000) -> Tuple[pd.DataFrame, pd.Series]:
    with Session_pool() as db:
        # –°–æ–±–µ—Ä—ë–º –ø–æ –æ–¥–Ω–æ–º—É –º–∞—Ç—á—É –≤—Å–µ 4 –ø—Ä–µ—Ñ–∏–∫—Å–∞ –∏ –æ–±—ä–µ–¥–∏–Ω–∏–º –≤ wide-—Ñ–æ—Ä–º–∞—Ç
        match_ids = (
            db.query(Feature.match_id)
            .group_by(Feature.match_id)
            .limit(limit_matches)
            .all()
        )
        match_ids = [r[0] for r in match_ids]
        if not match_ids:
            return pd.DataFrame(), pd.Series(dtype=float)

        rows = (
            db.query(Feature)
            .filter(Feature.match_id.in_(match_ids))
            .all()
        )

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –µ–¥–∏–Ω—ã–π wide DF
    records = {}
    for r in rows:
        d = r.as_dict()
        mid = d['match_id']
        pref = d['prefix']
        rec = records.setdefault(mid, {'match_id': mid})
        for k, v in d.items():
            if k in META or k in DROP_FIELD_EMBEDDING or k.startswith('_'):
                continue
            # –û—Å—Ç–∞–≤–∏–º —Ç–∞—Ä–≥–µ—Ç –¥–ª—è total_amount –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—É—é –∫–æ–ª–æ–Ω–∫—É
            if k == 'target_total_amount' and pref == 'home':
                rec['target_total_amount'] = v
            elif k in TARGET_FIELDS:
                continue
            else:
                rec[f'{pref}_{k}'] = v

    df = pd.DataFrame.from_dict(records, orient='index')

    # –ß–∏—Å—Ç–∏–º –∏ –ø—Ä–∏–≤–æ–¥–∏–º —Ç–∏–ø—ã
    y = pd.to_numeric(df['target_total_amount'], errors='coerce') if 'target_total_amount' in df.columns else pd.Series(dtype=float)
    X = df.drop(columns=[c for c in df.columns if c in ('target_total_amount', 'match_id')], errors='ignore')
    for c in X.columns:
        X[c] = pd.to_numeric(X[c], errors='coerce')
    X = X.fillna(0.0).astype(float)
    y = y.fillna(0.0).astype(float)

    return X, y


def main() -> None:
    print("\nüìä –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è target_total_amount (F, MI)")
    print("=" * 70)
    X, y = load_dataset()
    if X.empty or y.empty:
        print('–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞')
        return

    # F-statistic (–ª–∏–Ω–µ–π–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å)
    f_vals, _ = f_regression(X, y)
    f_vals = np.nan_to_num(f_vals)

    # Mutual Information (–Ω–µ–ª–∏–Ω–µ–π–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å)
    mi_vals = mutual_info_regression(X, y, random_state=42)

    df_scores = pd.DataFrame({
        'feature': X.columns,
        'F_value': f_vals,
        'MI': mi_vals
    }).sort_values(by='MI', ascending=False)

    print(f"–û–±—ä–µ–∫—Ç–æ–≤: {len(y):,}, –§–∏—á: {X.shape[1]:,}")
    print("\n–¢–æ–ø-30 –ø–æ MI:")
    for _, r in df_scores.head(30).iterrows():
        print(f"  {r['feature']}: MI={r['MI']:.5f}, F={r['F_value']:.2f}")


if __name__ == '__main__':
    main()


