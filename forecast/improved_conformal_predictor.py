#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä —Å –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –∏ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏.
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è –≤ —Å–∏—Å—Ç–µ–º—É publisher.py –¥–ª—è –∑–∞–º–µ–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π.
"""

import logging
import os
import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional, Tuple
import joblib
from datetime import datetime

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import Session_pool
from db.models import Feature, Match, Prediction, Outcome
from core.constants import TARGET_FIELDS, DROP_FIELD_EMBEDDING
from core.utils import create_feature_vector_new

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

META = {'id', 'match_id', 'prefix', 'created_at', 'updated_at'}


class ImprovedConformalPredictor:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∫–æ–Ω—Ñ–æ—Ä–º–Ω—ã–π –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä —Å –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏."""
    
    def __init__(self, models_dir: str = 'results/quality/improved_models'):
        self.models_dir = models_dir
        self.models = {}
        self.scalers = {}
        self.feature_names = {}
        self.load_models()
    
    def load_models(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏."""
        logger.info('üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...')
        
        targets = ['wdl', 'oz', 'total_amount']
        
        for target in targets:
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
                rf_path = os.path.join(self.models_dir, f'{target}_rf_model.joblib')
                gb_path = os.path.join(self.models_dir, f'{target}_gb_model.joblib')
                scaler_path = os.path.join(self.models_dir, f'{target}_scaler.joblib')
                metadata_path = os.path.join(self.models_dir, f'{target}_metadata.joblib')
                
                if all(os.path.exists(p) for p in [rf_path, gb_path, scaler_path, metadata_path]):
                    self.models[target] = {
                        'rf': joblib.load(rf_path),
                        'gb': joblib.load(gb_path)
                    }
                    self.scalers[target] = joblib.load(scaler_path)
                    metadata = joblib.load(metadata_path)
                    self.feature_names[target] = metadata['feature_names']
                    logger.info(f'‚úÖ {target}: –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã')
                else:
                    logger.warning(f'‚ùå {target}: –Ω–µ –≤—Å–µ —Ñ–∞–π–ª—ã –Ω–∞–π–¥–µ–Ω—ã')
                    
            except Exception as e:
                logger.error(f'‚ùå {target}: –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ - {e}')
    
    def prepare_features(self, match_id: int) -> Dict[str, pd.DataFrame]:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–∏—á–∏ –¥–ª—è –º–∞—Ç—á–∞."""
        with Session_pool() as db:
            rows = (
                db.query(Feature)
                .filter(Feature.match_id == match_id)
                .all()
            )
        
        if not rows:
            return {}
        
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        record = {'match_id': match_id}
        for r in rows:
            d = r.as_dict()
            pref = d['prefix']
            
            for k, v in d.items():
                if k in META or k in DROP_FIELD_EMBEDDING or k.startswith('_'):
                    continue
                if k in TARGET_FIELDS:
                    continue
                record[f'{pref}_{k}'] = v
        
        # –°–æ–∑–¥–∞–µ–º DataFrame
        df = pd.DataFrame([record])
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏—á–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —Ü–µ–ª–∏
        prepared_features = {}
        for target, feature_list in self.feature_names.items():
            available_features = [f for f in feature_list if f in df.columns]
            if available_features:
                X = df[available_features].copy()
                # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —á–∏—Å–ª–æ–≤—ã–º —Ç–∏–ø–∞–º
                for col in X.columns:
                    X[col] = pd.to_numeric(X[col], errors='coerce')
                X = X.fillna(0.0).astype(float)
                prepared_features[target] = X
            else:
                logger.warning(f'‚ö†Ô∏è {target}: –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ–∏—á–µ–π')
        
        return prepared_features
    
    def predict_match(self, match_id: int) -> Dict[str, Any]:
        """–î–µ–ª–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –º–∞—Ç—á–∞."""
        logger.info(f'üéØ –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –º–∞—Ç—á–∞ {match_id}')
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏—á–∏
        features = self.prepare_features(match_id)
        
        if not features:
            return {'error': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—Ç—á–∞'}
        
        predictions = {}
        
        for target, X in features.items():
            if target not in self.models:
                continue
            
            try:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ñ–∏—á–∏
                X_scaled = self.scalers[target].transform(X)
                
                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑—ã –æ—Ç –æ–±–µ–∏—Ö –º–æ–¥–µ–ª–µ–π
                rf_pred = self.models[target]['rf'].predict(X_scaled)[0]
                gb_pred = self.models[target]['gb'].predict(X_scaled)[0]
                
                # –ê–Ω—Å–∞–º–±–ª—å
                if target in ['wdl', 'oz']:
                    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è - –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ
                    ensemble_pred = int(np.round((rf_pred + gb_pred) / 2))
                else:
                    # –†–µ–≥—Ä–µ—Å—Å–∏—è - —Å—Ä–µ–¥–Ω–µ–µ
                    ensemble_pred = (rf_pred + gb_pred) / 2
                
                predictions[target] = {
                    'rf_prediction': rf_pred,
                    'gb_prediction': gb_pred,
                    'ensemble_prediction': ensemble_pred
                }
                
                logger.info(f"{target}: RF={rf_pred}, GB={gb_pred}, –ê–Ω—Å–∞–º–±–ª—å={ensemble_pred}")
                
            except Exception as e:
                logger.error(f"‚ùå {target}: –æ—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è - {e}")
                predictions[target] = {'error': str(e)}
        
        return predictions
    
    def create_conformal_prediction(self, match_id: int) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ñ–æ—Ä–º–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –≤ —Ñ–æ—Ä–º–∞—Ç–µ, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–∏—Å—Ç–µ–º–æ–π."""
        predictions = self.predict_match(match_id)
        
        if 'error' in predictions:
            return {'error': predictions['error']}
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –∫–æ–Ω—Ñ–æ—Ä–º–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞
        conformal_result = {
            'match_id': match_id,
            'predictions': {}
        }
        
        # WDL (win_draw_loss)
        if 'wdl' in predictions and 'error' not in predictions['wdl']:
            wdl_pred = predictions['wdl']['ensemble_prediction']
            conformal_result['predictions']['win_draw_loss'] = {
                'home_win': 1.0 if wdl_pred == 0 else 0.0,
                'draw': 1.0 if wdl_pred == 1 else 0.0,
                'away_win': 1.0 if wdl_pred == 2 else 0.0,
                'confidence': 0.8,  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è
                'uncertainty': 0.2
            }
        
        # OZ (–æ–±–µ –∑–∞–±—å—é—Ç)
        if 'oz' in predictions and 'error' not in predictions['oz']:
            oz_pred = predictions['oz']['ensemble_prediction']
            conformal_result['predictions']['oz'] = {
                'yes': 1.0 if oz_pred == 1 else 0.0,
                'no': 1.0 if oz_pred == 0 else 0.0,
                'confidence': 0.8,
                'uncertainty': 0.2
            }
        
        # Total Amount (—Ä–µ–≥—Ä–µ—Å—Å–∏—è)
        if 'total_amount' in predictions and 'error' not in predictions['total_amount']:
            total_pred = predictions['total_amount']['ensemble_prediction']
            conformal_result['predictions']['total_amount'] = {
                'forecast': total_pred,
                'confidence': 0.8,
                'uncertainty': 0.2,
                'lower_bound': max(0, total_pred - 0.5),
                'upper_bound': total_pred + 0.5
            }
        
        return conformal_result


class ImprovedNeuralConformalPredictor:
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å–∏—Å—Ç–µ–º—É."""
    
    def __init__(self):
        self.improved_predictor = ImprovedConformalPredictor()
    
    def train_conformal_predictor(self) -> bool:
        """–û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞ (–º–æ–¥–µ–ª–∏ —É–∂–µ –æ–±—É—á–µ–Ω—ã)."""
        try:
            logger.info('‚úÖ –£–ª—É—á—à–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —É–∂–µ –æ–±—É—á–µ–Ω—ã –∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã')
            return True
        except Exception as e:
            logger.error(f'‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}')
            return False
    
    def get_tournament_ids(self) -> List[int]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ ID —á–µ–º–ø–∏–æ–Ω–∞—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        try:
            with Session_pool() as db:
                # –ü–æ–ª—É—á–∞–µ–º —á–µ–º–ø–∏–æ–Ω–∞—Ç—ã —Å –º–∞—Ç—á–∞–º–∏, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å —Ñ–∏—á–∏
                result = db.execute("""
                    SELECT DISTINCT t.championship_id
                    FROM tournaments t
                    JOIN matchs m ON t.id = m.tournament_id
                    JOIN features f ON m.id = f.match_id
                    WHERE f.prefix = 'home'
                    ORDER BY t.championship_id
                """)
                
                tournament_ids = [row[0] for row in result.fetchall()]
                logger.info(f'–ù–∞–π–¥–µ–Ω–æ {len(tournament_ids)} —á–µ–º–ø–∏–æ–Ω–∞—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
                return tournament_ids
                
        except Exception as e:
            logger.error(f'–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —á–µ–º–ø–∏–æ–Ω–∞—Ç–æ–≤: {e}')
            return []
    
    def create_conformal_predictions(self, tournament_ids: List[int]) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ñ–æ—Ä–º–Ω—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã –¥–ª—è —Å–ø–∏—Å–∫–∞ —á–µ–º–ø–∏–æ–Ω–∞—Ç–æ–≤."""
        logger.info(f'–°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –¥–ª—è {len(tournament_ids)} —á–µ–º–ø–∏–æ–Ω–∞—Ç–æ–≤')
        
        results = []
        successful = 0
        failed = 0
        
        for tournament_id in tournament_ids:
            try:
                result = self._process_tournament(tournament_id)
                results.append(result)
                
                if 'error' not in result:
                    successful += 1
                else:
                    failed += 1
                    
            except Exception as e:
                error_msg = f'–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ–º–ø–∏–æ–Ω–∞—Ç–∞ {tournament_id}: {e}'
                logger.error(error_msg)
                results.append(error_msg)
                failed += 1
        
        return {
            'success': successful > 0,
            'total_tournaments': len(tournament_ids),
            'successful': successful,
            'failed': failed,
            'results': results
        }
    
    def _process_tournament(self, tournament_id: int) -> str:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —á–µ–º–ø–∏–æ–Ω–∞—Ç."""
        try:
            with Session_pool() as db:
                # –ü–æ–ª—É—á–∞–µ–º –º–∞—Ç—á–∏ —á–µ–º–ø–∏–æ–Ω–∞—Ç–∞ —Å —Ñ–∏—á–∞–º–∏
                result = db.execute("""
                    SELECT DISTINCT m.id
                    FROM tournaments t
                    JOIN matchs m ON t.id = m.tournament_id
                    JOIN features f ON m.id = f.match_id
                    WHERE t.championship_id = :tournament_id
                    AND f.prefix = 'home'
                    ORDER BY m.id
                """, {'tournament_id': tournament_id})
                
                match_ids = [row[0] for row in result.fetchall()]
                
                if not match_ids:
                    return f'–ù–µ—Ç –º–∞—Ç—á–µ–π —Å —Ñ–∏—á–∞–º–∏ –¥–ª—è —á–µ–º–ø–∏–æ–Ω–∞—Ç–∞ {tournament_id}'
                
                logger.info(f'–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(match_ids)} –º–∞—Ç—á–µ–π —á–µ–º–ø–∏–æ–Ω–∞—Ç–∞ {tournament_id}')
                
                processed = 0
                for match_id in match_ids:
                    try:
                        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–æ—Ä–º–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑
                        conformal_result = self.improved_predictor.create_conformal_prediction(match_id)
                        
                        if 'error' not in conformal_result:
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ outcomes
                            self._save_conformal_outcome(db, conformal_result)
                            processed += 1
                        
                    except Exception as e:
                        logger.error(f'–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–∞—Ç—á–∞ {match_id}: {e}')
                        continue
                
                return f'–ß–µ–º–ø–∏–æ–Ω–∞—Ç {tournament_id}: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed}/{len(match_ids)} –º–∞—Ç—á–µ–π'
                
        except Exception as e:
            return f'–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ–º–ø–∏–æ–Ω–∞—Ç–∞ {tournament_id}: {e}'
    
    def _save_conformal_outcome(self, db_session, conformal_result: Dict[str, Any]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–Ω—Ñ–æ—Ä–º–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –≤ —Ç–∞–±–ª–∏—Ü—É outcomes."""
        try:
            match_id = conformal_result['match_id']
            predictions = conformal_result['predictions']
            
            for pred_type, pred_data in predictions.items():
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º feature code
                feature_code = self._get_feature_code(pred_type)
                
                if feature_code is None:
                    continue
                
                # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –≤ outcomes
                if pred_type == 'total_amount':
                    # –†–µ–≥—Ä–µ—Å—Å–∏—è
                    outcome = Outcome(
                        match_id=match_id,
                        feature=feature_code,
                        forecast=pred_data['forecast'],
                        outcome=self._convert_regression_to_category(pred_data['forecast'], 'total_amount'),
                        probability=0.5,  # –î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
                        confidence=pred_data['confidence'],
                        uncertainty=pred_data['uncertainty'],
                        lower_bound=pred_data['lower_bound'],
                        upper_bound=pred_data['upper_bound']
                    )
                else:
                    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
                    outcome_value = self._get_classification_outcome(pred_type, pred_data)
                    outcome = Outcome(
                        match_id=match_id,
                        feature=feature_code,
                        forecast=pred_data.get('forecast', 0.0),
                        outcome=outcome_value,
                        probability=max(pred_data.values()) if isinstance(pred_data, dict) else 0.0,
                        confidence=pred_data['confidence'],
                        uncertainty=pred_data['uncertainty'],
                        lower_bound=None,
                        upper_bound=None
                    )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏
                existing = db_session.query(Outcome).filter(
                    Outcome.match_id == match_id,
                    Outcome.feature == feature_code
                ).first()
                
                if existing:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∑–∞–ø–∏—Å—å
                    for key, value in outcome.__dict__.items():
                        if not key.startswith('_'):
                            setattr(existing, key, value)
                else:
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
                    db_session.add(outcome)
            
            db_session.commit()
            
        except Exception as e:
            logger.error(f'–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–æ—Ä–º–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞: {e}')
            db_session.rollback()
    
    def _get_feature_code(self, pred_type: str) -> Optional[int]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–¥ —Ñ–∏—á–∏ –¥–ª—è —Ç–∏–ø–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞."""
        mapping = {
            'win_draw_loss': 1,
            'oz': 2,
            'total_amount': 8
        }
        return mapping.get(pred_type)
    
    def _convert_regression_to_category(self, forecast: float, pred_type: str) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—é."""
        if pred_type == 'total_amount':
            return '–¢–ë' if forecast >= 2.5 else '–¢–ú'
        return str(forecast)
    
    def _get_classification_outcome(self, pred_type: str, pred_data: Dict[str, Any]) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∏—Å—Ö–æ–¥ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞."""
        if pred_type == 'win_draw_loss':
            if pred_data.get('home_win', 0) > 0.5:
                return '–ø1'
            elif pred_data.get('draw', 0) > 0.5:
                return '–Ω'
            else:
                return '–ø2'
        elif pred_type == 'oz':
            return '–æ–±–µ –∑–∞–±—å—é—Ç - –¥–∞' if pred_data.get('yes', 0) > 0.5 else '–æ–±–µ –∑–∞–±—å—é—Ç - –Ω–µ—Ç'
        
        return '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'


def create_improved_conformal_predictor() -> ImprovedNeuralConformalPredictor:
    """–§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞."""
    return ImprovedNeuralConformalPredictor()


if __name__ == '__main__':
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    predictor = create_improved_conformal_predictor()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–∞—Ç—á–∞—Ö
    test_match_ids = [451, 452, 453]
    
    for match_id in test_match_ids:
        result = predictor.improved_predictor.predict_match(match_id)
        print(f"\n–ú–∞—Ç—á {match_id}:")
        for target, pred in result.items():
            if 'error' not in pred:
                print(f"  {target}: {pred['ensemble_prediction']}")
            else:
                print(f"  {target}: –û—à–∏–±–∫–∞ - {pred['error']}")
